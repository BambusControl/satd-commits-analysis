{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau, mannwhitneyu\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class OurDataFrame(NamedTuple):\n",
    "    with_outliers: pd.DataFrame\n",
    "\n",
    "\n",
    "# https://saturncloud.io/blog/how-to-detect-and-exclude-outliers-in-a-pandas-dataframe/\n",
    "def find_outliers(\n",
    "    data: pd.DataFrame,\n",
    "    column: str,\n",
    "    threshold: float = 1.5,\n",
    "    quantile_1: float = 0.25,\n",
    "    quantile_2: float = 0.75,\n",
    ") -> pd.DataFrame:\n",
    "    q1 = data[column].quantile(quantile_1)\n",
    "    q2 = data[column].quantile(quantile_2)\n",
    "    iqr = q2 - q1\n",
    "\n",
    "    return data[\n",
    "        (data[column] < q1 - threshold * iqr)\n",
    "        |\n",
    "        (data[column] > q2 + threshold * iqr)\n",
    "        ]\n",
    "\n",
    "\n",
    "def drop_outliers(data: pd.DataFrame, columns: Iterable[str]) -> pd.DataFrame:\n",
    "    # Identify outliers in source data\n",
    "    column_outliers = [\n",
    "        find_outliers(data, column)\n",
    "        for column in columns\n",
    "    ]\n",
    "\n",
    "    # Drop outliers from source data\n",
    "    datacopy = data.copy()\n",
    "    total_outliers = sum(len(outliers) for outliers in column_outliers)\n",
    "\n",
    "    print(\n",
    "        f\"Dropping {100 * total_outliers / len(datacopy):.2f}% outliers ({total_outliers} out of {len(datacopy)}) for columns {columns}\")\n",
    "\n",
    "    for outliers in column_outliers:\n",
    "        # We ignore errors, because one row can be an outlier in multiple columns\n",
    "        datacopy = datacopy.drop(outliers.index, errors=\"ignore\")\n",
    "\n",
    "    return datacopy\n",
    "\n",
    "\n",
    "def column_no_outliers_or_na(data: pd.DataFrame, column: str) -> pd.Series:\n",
    "    return drop_outliers(data, [column])[column].dropna()\n",
    "\n",
    "\n",
    "def columns_no_outliers_or_na(data: pd.DataFrame, out_cols: Iterable[str], add_cols: Iterable[str]) -> pd.DataFrame:\n",
    "    cols = list(out_cols) + list(add_cols)\n",
    "    return drop_outliers(data, out_cols)[cols].dropna()\n",
    "\n",
    "\n",
    "def load_data(path: Path) -> OurDataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File {path} does not exist\")\n",
    "\n",
    "    raw_data = pd.read_csv(path)\n",
    "    column_filtered_data = raw_data[[\n",
    "        'project',\n",
    "        'classification',\n",
    "        'net_lines',\n",
    "        'num_files',\n",
    "        'dmm_unit_complexity',\n",
    "    ]]\n",
    "\n",
    "    # Drop rows with NaN in all the selected columns\n",
    "    no_nan_data = column_filtered_data.dropna(\n",
    "        subset=[\n",
    "            'net_lines',\n",
    "            'num_files',\n",
    "            'dmm_unit_complexity',\n",
    "        ],\n",
    "        how='all',\n",
    "    )\n",
    "\n",
    "    print(f\"[{len(raw_data)}] raw data rows\")\n",
    "    print(f\"[{len(column_filtered_data)}] column filtered data rows\")\n",
    "    print(f\"[{len(no_nan_data)}] no NaN data rows\")\n",
    "    # print(f\"\\t[{len(data)}] outlier filtered data rows\")\n",
    "\n",
    "    return OurDataFrame(\n",
    "        with_outliers=no_nan_data.copy(),\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "DATA = load_data(Path(\"../data/satd-commits-merged-dataset.csv\"))\n",
    "# Helpful iterator for all the stuff."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2430a381830d5088",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation Between (all) Debt and Non-Debt via a given metric"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6adb4d0927459488"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def correlation_between_debt_and_non_debt(df_dumm: pd.DataFrame, metric: str):\n",
    "    # Kendall needs the same size for both cols.\n",
    "    nona_df = df_dumm[[\"classification\", metric]].dropna(how=\"any\")\n",
    "\n",
    "    # Select the two columns\n",
    "    debt_df = nona_df[nona_df[\"classification\"] != \"non_debt\"][metric]\n",
    "    non_debt_df = nona_df[nona_df[\"classification\"] == \"non_debt\"][metric]\n",
    "\n",
    "    # Ensure both datasets are the same size\n",
    "    min_size = min(len(debt_df), len(non_debt_df))\n",
    "    if len(debt_df) > min_size:\n",
    "        debt_df = debt_df.sample(n=min_size, random_state=42)  # Randomly sample to match size\n",
    "    elif len(non_debt_df) > min_size:\n",
    "        non_debt_df = non_debt_df.sample(n=min_size, random_state=42)  # Randomly sample to match size\n",
    "\n",
    "    stat_val, p_value = kendalltau(debt_df, non_debt_df)\n",
    "\n",
    "    # Comparing the p-value to a significance level (e.g., 0.05)\n",
    "    alpha = 0.05\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"stat_val\": stat_val,\n",
    "        \"p_value\": p_value,\n",
    "        \"reject_null\": p_value < alpha,\n",
    "    }\n",
    "\n",
    "\n",
    "def all_correlation_between_debt_and_non_debt():\n",
    "    metrics = {\n",
    "        'net_lines',\n",
    "        'num_files',\n",
    "        'dmm_unit_complexity'\n",
    "    }\n",
    "\n",
    "    _data =DATA.with_outliers.copy()\n",
    "\n",
    "    results = (\n",
    "        correlation_between_debt_and_non_debt(_data, metric)\n",
    "        for metric in metrics\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "cor_debt_to_non_debt = all_correlation_between_debt_and_non_debt()\n",
    "cor_debt_to_non_debt.sort_values(by=[\"metric\"], inplace=True)\n",
    "cor_debt_to_non_debt.to_csv(\"../data/out/debt_to_non_debt_test_all.csv\", index=False)\n",
    "\n",
    "metrics = {\n",
    "    'net_lines',\n",
    "    'num_files',\n",
    "    'dmm_unit_complexity'\n",
    "}\n",
    "\n",
    "for (mtric, datafr) in ((metric, cor_debt_to_non_debt[cor_debt_to_non_debt[\"metric\"] == metric]) for metric in metrics):\n",
    "    datafr.to_csv(\n",
    "        f\"../data/out/debt_to_non_debt_test_{mtric}.csv\",\n",
    "        columns=[\"metric\", \"stat_val\", \"p_value\", \"reject_null\"],\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "cor_debt_to_non_debt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d689bea30412bc69",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation Between SATD Classes (being a binary 1/0) and Metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4092a56c9aee5c08"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def correlation_between_class_and_a_metric(df_dumm: pd.DataFrame, satd_class: str, metric: str):\n",
    "    # Kendall needs the same size for both cols.\n",
    "    nona_df = df_dumm[[f'classification_{satd_class}', metric]].dropna(how=\"any\")\n",
    "\n",
    "    # Select the two columns\n",
    "    cls_df = nona_df[f'classification_{satd_class}']\n",
    "    mtr_df = nona_df[metric]\n",
    "\n",
    "    stat_val, p_value = kendalltau(cls_df, mtr_df)\n",
    "\n",
    "    # Comparing the p-value to a significance level (e.g., 0.05)\n",
    "    alpha = 0.05\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"satd_class\": satd_class,\n",
    "        \"stat_val\": stat_val,\n",
    "        \"p_value\": p_value,\n",
    "        \"reject_null\": p_value < alpha,\n",
    "    }\n",
    "\n",
    "\n",
    "def all_correlation_between_class_and_a_metric():\n",
    "    metrics = {\n",
    "        'net_lines',\n",
    "        'num_files',\n",
    "        'dmm_unit_complexity'\n",
    "    }\n",
    "\n",
    "    satd_classes = {\n",
    "        'architecture_debt',\n",
    "        'build_debt',\n",
    "        'code_debt',\n",
    "        'design_debt',\n",
    "        'documentation_debt',\n",
    "        'non_debt',\n",
    "        'requirement_debt',\n",
    "        'test_debt',\n",
    "    }\n",
    "\n",
    "    one_hot_dataframe = pd.get_dummies(DATA.with_outliers, columns=['classification'])\n",
    "\n",
    "    dataframes = {\n",
    "        metric: drop_outliers(one_hot_dataframe, [metric])\n",
    "        for metric in metrics\n",
    "    }\n",
    "\n",
    "    results = (\n",
    "        correlation_between_class_and_a_metric(dataframe, satd_class, metric)\n",
    "        for satd_class in satd_classes\n",
    "        for (metric, dataframe) in dataframes.items()\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "cor_cls_to_mtr = all_correlation_between_class_and_a_metric()\n",
    "cor_cls_to_mtr.sort_values(by=[\"metric\", \"satd_class\"], inplace=True)\n",
    "cor_cls_to_mtr.to_csv(\"../data/out/satd_class_to_metric_test_all.csv\", index=False)\n",
    "\n",
    "metrics = {\n",
    "    'net_lines',\n",
    "    'num_files',\n",
    "    'dmm_unit_complexity'\n",
    "}\n",
    "\n",
    "for (mtric, datafr) in ((metric, cor_cls_to_mtr[cor_cls_to_mtr[\"metric\"] == metric]) for metric in metrics):\n",
    "    datafr.to_csv(\n",
    "        f\"../data/out/satd_class_to_metric_test_{mtric}.csv\",\n",
    "        columns=[\"metric\", \"satd_class\", \"stat_val\", \"p_value\", \"reject_null\"],\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "new_df = cor_cls_to_mtr.pivot(columns='metric', index='satd_class', values=\"stat_val\")\n",
    "new_df.to_csv(f\"../data/out/satd_class_to_metric_test_pivot_stat_val.csv\")\n",
    "\n",
    "cor_cls_to_mtr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b15b41d21b3199",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_heatmap_class_to_metric(me_df: pd.DataFrame, value: str, colormap: str = 'Pastel1', clim=None):\n",
    "    # me_df = me_df[me_df['metric'] == metric]\n",
    "    _font_size = 24\n",
    "    me_df = me_df.pivot(index='metric', columns='satd_class', values=value)\n",
    "    plt.matshow(me_df, cmap=colormap)\n",
    "    if clim is not None:\n",
    "        plt.clim(clim)\n",
    "    plt.xticks(range(len(me_df.columns)), me_df.columns, rotation=90, fontsize=_font_size)\n",
    "    plt.yticks(range(len(me_df.index)), me_df.index, fontsize=_font_size)\n",
    "    clb = plt.colorbar()\n",
    "    clb.set_ticks(\n",
    "        ticks=[\n",
    "            False,\n",
    "            True\n",
    "        ],\n",
    "        labels=[\n",
    "            \"Insignificant diff.\\nNull H. not rejected\",\n",
    "            \"Significant diff.\\nNull H. rejected\"\n",
    "        ]\n",
    "    )\n",
    "    clb.ax.tick_params(labelsize=_font_size)\n",
    "    folder = \"satd_class_to_metric\"\n",
    "    out_path = f\"../data/out/imgs/{folder}\"\n",
    "    Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(f\"{out_path}/class_to_metric_{value}.png\", bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plots_class_to_metric(data: pd.DataFrame):\n",
    "    df = data.copy()\n",
    "\n",
    "    values = {\n",
    "        # (\"stat_val\", \"coolwarm\", (-1, 1)),\n",
    "        # (\"p_value\", \"Pastel1\", None),\n",
    "        (\"reject_null\", \"summer\", (False, True)),\n",
    "    }\n",
    "\n",
    "    for (value, colormap, clim) in values:\n",
    "        plot_heatmap_class_to_metric(df, value, \"summer\", clim)\n",
    "\n",
    "\n",
    "plots_class_to_metric(cor_cls_to_mtr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80677c958f915860",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correlation Between Class A and Class B via a given Metric"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9566e14f279ca84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def manwh_between_classes_for_a_metric(df: pd.DataFrame, cls_a: str, cls_b: str, metric: str):\n",
    "    # Assuming df is your pandas DataFrame containing the relevant data\n",
    "    # Selecting data for architecture_debt and code_debt\n",
    "    a_df = df[df['classification'] == cls_a][metric]\n",
    "    b_df = df[df['classification'] == cls_b][metric]\n",
    "\n",
    "    stat_val, p_value = mannwhitneyu(a_df.dropna(), b_df.dropna())\n",
    "\n",
    "    # Comparing the p-value to a significance level (e.g., 0.05)\n",
    "    alpha = 0.05\n",
    "\n",
    "    return {\n",
    "        \"metric\": metric,\n",
    "        \"class_a\": cls_a,\n",
    "        \"class_b\": cls_b,\n",
    "        \"stat_val\": stat_val,\n",
    "        \"p_value\": p_value,\n",
    "        # \"alpha\": alpha,\n",
    "        \"reject_null\": p_value < alpha,\n",
    "        # \"result\": \"Reject Null (significant)\" if p_value < alpha else \"Fail to reject Null (not significant)\"\n",
    "    }\n",
    "\n",
    "\n",
    "def all_manwh_between_classes_for_a_metric():\n",
    "    metrics = {\n",
    "        'net_lines',\n",
    "        'num_files',\n",
    "        'dmm_unit_complexity'\n",
    "    }\n",
    "\n",
    "    satd_classes = {\n",
    "        'architecture_debt',\n",
    "        'build_debt',\n",
    "        'code_debt',\n",
    "        'design_debt',\n",
    "        'documentation_debt',\n",
    "        'non_debt',\n",
    "        'requirement_debt',\n",
    "        'test_debt',\n",
    "    }\n",
    "\n",
    "    df = {\n",
    "        metric: drop_outliers(DATA.with_outliers, [metric])\n",
    "        for metric in metrics\n",
    "    }\n",
    "\n",
    "    results = (\n",
    "        manwh_between_classes_for_a_metric(dataframe, cls_a, cls_b, metric)\n",
    "        for cls_a, cls_b\n",
    "        in itertools.product(satd_classes, satd_classes)\n",
    "        for (metric, dataframe) in df.items()\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "mw_cls_to_cls = all_manwh_between_classes_for_a_metric()\n",
    "mw_cls_to_cls.sort_values(by=[\"metric\", \"class_a\", \"class_b\"], inplace=True)\n",
    "mw_cls_to_cls.to_csv(\"../data/out/satd_class_test_all.csv\", index=False)\n",
    "\n",
    "metrics = {\n",
    "    'net_lines',\n",
    "    'num_files',\n",
    "    'dmm_unit_complexity'\n",
    "}\n",
    "\n",
    "for (mtric, datafr) in ((metric, mw_cls_to_cls[mw_cls_to_cls[\"metric\"] == metric]) for metric in metrics):\n",
    "    datafr.to_csv(\n",
    "        f\"../data/out/satd_class_test_{mtric}.csv\",\n",
    "        columns=[\"class_a\", \"class_b\", \"stat_val\", \"p_value\", \"reject_null\"],\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "mw_cls_to_cls"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f27bda1031f5424",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_heatmap(me_df: pd.DataFrame, metric: str, value: str, colormap: str = 'Pastel1'):\n",
    "    me_df = me_df[me_df['metric'] == metric]\n",
    "    me_df = me_df.pivot(index='class_a', columns='class_b', values=value)\n",
    "    plt.matshow(me_df, cmap=colormap)\n",
    "    plt.xticks(range(len(me_df.columns)), me_df.columns, rotation=90)\n",
    "    plt.yticks(range(len(me_df.columns)), me_df.columns)\n",
    "    clb = plt.colorbar()\n",
    "    clb.set_ticks(\n",
    "        ticks=[\n",
    "            False,\n",
    "            True\n",
    "        ],\n",
    "        labels=[\n",
    "            \"Insignificant diff.\\nNull H. not rejected\",\n",
    "            \"Significant diff.\\nNull H. rejected\"\n",
    "        ]\n",
    "    )\n",
    "    folder = \"satd_class_test\"\n",
    "    out_path = f\"../data/out/imgs/{folder}\"\n",
    "    Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(f\"{out_path}/heatmap_{metric}_{value}.png\", bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plots():\n",
    "    df = mw_cls_to_cls.copy()\n",
    "    metrics = {\n",
    "        'net_lines',\n",
    "        'num_files',\n",
    "        'dmm_unit_complexity'\n",
    "    }\n",
    "    values = {\n",
    "        # (\"stat_val\", \"coolwarm\"),\n",
    "        # (\"p_value\", \"Pastel1\"),\n",
    "        (\"reject_null\", \"summer\"),\n",
    "    }\n",
    "\n",
    "    for (metric, (value, colormap)) in itertools.product(metrics, values):\n",
    "        plot_heatmap(df, metric, value, \"summer\")\n",
    "\n",
    "\n",
    "plots()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "729f04bf2d9c80d5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f960cd602e054b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from scipy.stats import ranksums, mannwhitneyu, kendalltau\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "data = pd.read_csv('../data/satd-commits-merged-dataset.csv').filter(\n",
    "    items=['classification', 'num_files', 'net_lines', 'dmm_unit_complexity'])\n",
    "\n",
    "\n",
    "def mask_outliers(df, replace):\n",
    "    # Calculate Q1 and Q2 quantile\n",
    "    q = df.agg('quantile', q=[.25, .75])\n",
    "\n",
    "    # Calculate IQR = Q2 - Q1\n",
    "    iqr = q.loc[.75] - q.loc[.25]\n",
    "\n",
    "    # Calculate lower and upper limits to decide outliers\n",
    "    lower = q.loc[.25] - 1.5 * iqr\n",
    "    upper = q.loc[.75] + 1.5 * iqr\n",
    "\n",
    "    # Replace the values that does not lies between [lower, upper]\n",
    "    return df.where(df.ge(lower) & df.le(upper), replace)\n",
    "\n",
    "\n",
    "removed_outliers: DataFrame = mask_outliers(data[['num_files', 'net_lines', 'dmm_unit_complexity']], np.nan).join(\n",
    "    data['classification'])\n",
    "\n",
    "fig2, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
    "print(max(removed_outliers['dmm_unit_complexity']))\n",
    "# Plot the first histogram (Num files changed distribution)\n",
    "axes[0].hist(removed_outliers['num_files'], edgecolor='black', bins=np.arange(14) - 0.5)\n",
    "axes[0].set_title('Num files changed distribution, outliers removed')\n",
    "axes[0].set_xticks(range(14))\n",
    "\n",
    "# Plot the second histogram (Net lines changed distribution)\n",
    "bins = np.linspace(min(removed_outliers['net_lines']), max(removed_outliers['net_lines']), 50)\n",
    "axes[1].hist(removed_outliers['net_lines'], edgecolor='black', bins=bins - 0.5)\n",
    "axes[1].set_title('Net lines changed distribution, outliers removed')\n",
    "\n",
    "# Plot the second histogram (Net lines changed distribution)\n",
    "bins2 = np.linspace(min(removed_outliers['dmm_unit_complexity']), max(removed_outliers['dmm_unit_complexity']), 15)\n",
    "axes[2].hist(removed_outliers['dmm_unit_complexity'], edgecolor='black', bins=bins2)\n",
    "axes[2].set_title('dmm unit complexity change distribution, outliers removed')\n",
    "# axes[0].set_xticks(range(14))\n",
    "\n",
    "non_debt_dataset = removed_outliers[removed_outliers['classification'] == 'non_debt']\n",
    "debt_dataset = removed_outliers[removed_outliers['classification'] != 'non_debt']\n",
    "\n",
    "classifiers_simplified_dataset = removed_outliers.copy()\n",
    "classifiers_simplified_dataset.loc[\n",
    "    classifiers_simplified_dataset['classification'] != 'non_debt', 'classification'] = 'debt'\n",
    "\n",
    "# create boxplots for debt vs non-debt\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 20))\n",
    "\n",
    "classifiers_simplified_dataset.boxplot(by='classification', column=['net_lines'], showfliers=False, ax=axes[0])\n",
    "axes[0].set_title('Boxplot of net_lines by classification')\n",
    "axes[0].set_ylabel('net_lines')\n",
    "\n",
    "classifiers_simplified_dataset.boxplot(by='classification', column=['num_files'], showfliers=False, ax=axes[1])\n",
    "axes[1].set_title('Boxplot of num_files by classification')\n",
    "axes[1].set_ylabel('num_files')\n",
    "\n",
    "classifiers_simplified_dataset.boxplot(by='classification', column=['dmm_unit_complexity'], showfliers=False,\n",
    "                                       ax=axes[2])\n",
    "axes[2].set_title('Boxplot of dmm_unit_complexity by classification')\n",
    "axes[2].set_ylabel('dmm_unit_complexity')\n",
    "\n",
    "# Create boxplots for all classifications\n",
    "fig.suptitle(None, fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "fig.subplots_adjust(bottom=0.05)\n",
    "fig.subplots_adjust(left=0.05)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 20))\n",
    "\n",
    "removed_outliers.boxplot(by='classification', column=['net_lines'], showfliers=False, ax=axes[0])\n",
    "axes[0].set_title('Boxplot of net_lines by classification')\n",
    "axes[0].set_ylabel('net_lines')\n",
    "\n",
    "removed_outliers.boxplot(by='classification', column=['num_files'], showfliers=False, ax=axes[1])\n",
    "axes[1].set_title('Boxplot of num_files by classification')\n",
    "axes[1].set_ylabel('num_files')\n",
    "\n",
    "removed_outliers.boxplot(by='classification', column=['dmm_unit_complexity'], showfliers=False, ax=axes[2])\n",
    "axes[2].set_title('Boxplot of dmm_unit_complexity by classification')\n",
    "axes[2].set_ylabel('dmm_unit_complexity')\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "fig.suptitle(None, fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "fig.subplots_adjust(bottom=0.05)\n",
    "\n",
    "# Create an empty DataFrame\n",
    "result_df = pd.DataFrame(columns=['Comparison', 'Statistic', 'P-value', 'Length of Debt Data'])\n",
    "\n",
    "\n",
    "# Function to perform Mann-Whitney U test and append the result to the DataFrame\n",
    "def perform_mannwhitneyu(data1, data2, name):\n",
    "    stat, p_value = mannwhitneyu(data1, data2)\n",
    "    result_df.loc[len(result_df)] = [name, stat, p_value, len(data2)]\n",
    "\n",
    "\n",
    "# Mann-Whitney U tests for each classification compared to non-debt\n",
    "for name, group in debt_dataset.groupby('classification'):\n",
    "    perform_mannwhitneyu(non_debt_dataset['net_lines'].dropna(), group['net_lines'].dropna(), f\"{name}/net_lines\")\n",
    "    perform_mannwhitneyu(non_debt_dataset['num_files'].dropna(), group['num_files'].dropna(), f\"{name}/num_files\")\n",
    "    perform_mannwhitneyu(non_debt_dataset['dmm_unit_complexity'].dropna(), group['dmm_unit_complexity'].dropna(),\n",
    "                         f\"{name}/dmm_unit_complexity\")\n",
    "\n",
    "# Overall Mann-Whitney U tests\n",
    "perform_mannwhitneyu(non_debt_dataset['net_lines'].dropna(), debt_dataset['net_lines'].dropna(), 'debt/net_lines')\n",
    "perform_mannwhitneyu(non_debt_dataset['num_files'].dropna(), debt_dataset['num_files'].dropna(), 'debt/num_files')\n",
    "perform_mannwhitneyu(non_debt_dataset['dmm_unit_complexity'].dropna(), debt_dataset['dmm_unit_complexity'].dropna(),\n",
    "                     'debt/dmm_unit_complexity')\n",
    "\n",
    "# Display the result DataFrame\n",
    "print(result_df)\n",
    "# print to csv\n",
    "result_df.to_csv('mannwhitneyu.csv')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee530847f2ff436c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
